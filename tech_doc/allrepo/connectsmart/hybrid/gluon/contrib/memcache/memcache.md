# Python Memcached Client Implementation

üîç **Quick Summary (TL;DR)**
Full-featured Python memcached client supporting distributed caching, compression, pickling, multi-server pools, and advanced operations like CAS (Compare-And-Swap) with comprehensive error handling and connection management.

**Core functionality keywords**: memcached | distributed-cache | client | compression | pickle | multi-server | cas | threading | connection-pool

**Primary use cases**: High-performance web application caching, distributed system data sharing, session storage, database query caching

**Quick compatibility info**: Python 2.7+/3.x, memcached protocol 1.x, supports IPv4/IPv6/Unix sockets, thread-safe implementation

‚ùì **Common Questions Quick Index**
- Q: How does server selection work? A: Uses consistent hashing with configurable weights and automatic failover
- Q: Can it handle server failures? A: Yes, marks dead servers and retries after configurable interval
- Q: Does it support compression? A: Yes, automatic zlib compression for values above threshold
- Q: How does CAS work? A: Compare-And-Swap prevents race conditions in concurrent updates
- Q: Is it thread-safe? A: Yes, uses thread-local storage and proper connection management
- Q: What about Unicode strings? A: Requires explicit encoding to bytes, validates key format
- Q: How are large values handled? A: Configurable size limits, automatic rejection of oversized data
- Q: Can I use custom serialization? A: Yes, supports custom pickler/unpickler functions

üìã **Functionality Overview**
**Non-technical explanation**: Like a sophisticated mail sorting system that can send packages (data) to multiple post offices (memcached servers), automatically choosing the best route, compressing large packages, and handling situations when some post offices are temporarily closed.

**Technical explanation**: Production-grade memcached client implementing the complete memcached protocol with intelligent server selection, automatic failover, data compression, serialization, and comprehensive error handling for enterprise applications.

**Business value**: Enables high-performance distributed caching infrastructure essential for scalable web applications, reducing database load and improving user experience through faster response times.

**Context within larger system**: Core caching infrastructure component used by web frameworks, application servers, and distributed systems requiring fast, reliable data access.

üîß **Technical Specifications**
- **File information**: memcache.py, 1579 lines, Python module, high complexity with protocol implementation
- **Dependencies**: binascii, socket, threading, time, zlib, pickle, six (Python 2/3 compatibility)
- **Compatibility matrix**: Python 2.7+ and 3.x, memcached 1.x protocol, supports all socket families
- **Configuration parameters**: servers, debug, socket_timeout (3s), dead_retry (30s), compression thresholds
- **System requirements**: Network access to memcached servers, optional zlib for compression
- **Security requirements**: Network security, trusted data for pickle operations, key validation

üìù **Detailed Code Analysis**
- **Main function signatures**:
  - `Client(servers, debug=0, socket_timeout=3, dead_retry=30)` - Main client class
  - `get(key)`, `set(key, val, time=0)` - Basic cache operations
  - `get_multi(keys)`, `set_multi(mapping)` - Batch operations
  - `incr(key, delta=1)`, `decr(key, delta=1)` - Atomic counter operations
- **Execution flow**: Key validation ‚Üí Server selection ‚Üí Connection management ‚Üí Protocol communication ‚Üí Response parsing
- **Important code snippets**:
```python
# Multi-server setup with weights
mc = Client([('192.168.1.1:11211', 3), ('192.168.1.2:11211', 1)])

# Batch operations for efficiency
values = mc.get_multi(['user:123', 'user:456', 'user:789'])
mc.set_multi({'session:abc': data1, 'session:def': data2}, time=3600)

# Atomic operations
page_views = mc.incr('page_views', 1)
```
- **Design patterns**: Connection pooling, consistent hashing, factory pattern for host objects
- **Error handling**: Dead server detection, automatic retry logic, connection failure recovery
- **Memory usage**: Efficient binary protocol handling, optional compression, connection reuse

üöÄ **Usage Methods**
- **Basic client setup**:
```python
import memcache
mc = memcache.Client(['127.0.0.1:11211'], debug=1)
mc.set("key", "value", time=3600)
value = mc.get("key")
```
- **Multi-server configuration**:
```python
# Weighted server pool
servers = [
    ('cache1.example.com:11211', 3),  # 75% of keys
    ('cache2.example.com:11211', 1)   # 25% of keys
]
mc = memcache.Client(servers, socket_timeout=5)
```
- **Advanced operations**:
```python
# Batch operations
data = {'user:1': user1, 'user:2': user2, 'user:3': user3}
failed_keys = mc.set_multi(data, time=3600, key_prefix='cache:')

users = mc.get_multi(['user:1', 'user:2'], key_prefix='cache:')

# Atomic increment/decrement
counter = mc.incr('page_views', delta=5)
if counter is None:  # Key doesn't exist
    mc.set('page_views', 5)
```
- **Connection management**:
```python
# Check server statistics
stats = mc.get_stats()
for server, data in stats:
    print(f"{server}: {data['cmd_get']} gets, {data['bytes']} bytes")

# Flush all data
mc.flush_all()

# Clean shutdown
mc.disconnect_all()
```

üìä **Output Examples**
- **Successful operations**:
  - `set()` returns 1 for success, 0 for failure
  - `get()` returns stored value or None if not found
  - `incr()` returns new value after increment
- **Batch operations**:
  - `get_multi(['a', 'b', 'c'])` returns `{'a': value1, 'c': value3}` (missing 'b')
  - `set_multi()` returns list of keys that failed to store
- **Server statistics example**:
  ```python
  [('127.0.0.1:11211 (1)', {'uptime': '12345', 'curr_items': '50', 'bytes': '1024'})]
  ```
- **Error conditions**: Socket timeouts, connection refused, server marked dead
- **Performance metrics**: ~0.1ms local network latency, 10K+ ops/sec typical throughput

‚ö†Ô∏è **Important Notes**
- **Security considerations**:
  - Network traffic unencrypted by default - use VPN/TLS for sensitive data
  - Pickle serialization security risk with untrusted data
  - Key validation prevents injection attacks
  - Server access control important for data isolation
- **Permission requirements**: Network connectivity to memcached ports (11211 default)
- **Common troubleshooting**:
  - "Connection refused" ‚Üí Check memcached server running and firewall
  - "Key too long" ‚Üí Limit keys to 250 characters
  - "Value too large" ‚Üí Check SERVER_MAX_VALUE_LENGTH (1MB default)
  - Server marked dead ‚Üí Check dead_retry timeout and server health
- **Performance gotchas**: 
  - Large object serialization overhead
  - Network latency amplification
  - Hash distribution imbalance with few servers
- **Breaking changes**: Memcached server restarts lose all data
- **Backup considerations**: Cache is ephemeral, ensure application works without cache

üîó **Related File Links**
- **Project structure**: Part of gluon/contrib/memcache/ package
- **Related files**:
  - __init__.py (web2py integration wrapper)
  - System memcached configuration files
  - Application code using memcached
- **Configuration files**: Memcached server configuration, network setup
- **Test files**: Comprehensive doctests and unit tests included
- **Documentation**: Memcached protocol specification, deployment guides

üìà **Use Cases**
- **Web application caching**: Session data, user profiles, computed results
- **Database query caching**: Expensive query results, aggregated data
- **API response caching**: External service responses, rate limiting data
- **Content delivery**: Rendered pages, static content metadata
- **Distributed coordination**: Shared counters, locks, temporary state
- **Gaming applications**: Leaderboards, player sessions, real-time state
- **Anti-patterns**: Persistent data storage, security-sensitive information, very small frequently-changing data

üõ†Ô∏è **Improvement Suggestions**
- **Code optimization**:
  - Connection pooling per server for better concurrency
  - Binary protocol support for improved performance
  - Async/await support for non-blocking operations
- **Feature expansion**:
  - TLS/SSL support for encrypted communication
  - Consistent hashing algorithms (ketama, ring hash)
  - Advanced compression algorithms (lz4, snappy)
  - Metrics and monitoring integration
- **Technical debt**:
  - Modern Python 3 idioms and type hints
  - Configuration file support
  - Plugin architecture for serialization backends
- **Maintenance recommendations**:
  - Regular server health monitoring
  - Network latency and throughput analysis
  - Memory usage optimization and tuning
  - Security audit for production deployments
- **Monitoring improvements**:
  - Comprehensive metrics collection
  - Performance profiling and bottleneck analysis
  - Automated failover testing and validation

üè∑Ô∏è **Document Tags**
- **Keywords**: memcached, distributed-cache, client, high-performance, caching, compression, pickle, multi-server, cas, threading, connection-pool, protocol
- **Technical tags**: #memcached #caching #distributed-systems #performance #python #networking #serialization
- **Target roles**: Backend developers, DevOps engineers, system architects, performance engineers, infrastructure teams
- **Difficulty level**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 - requires understanding of distributed systems and networking)
- **Maintenance level**: Medium-High (requires infrastructure monitoring and tuning)
- **Business criticality**: Critical (essential for high-performance applications)
- **Related topics**: Distributed caching, memcached administration, network programming, serialization, high-availability systems