# HNTB Tow and Go Migration Documentation

## Quick Summary

The HNTB Tow and Go migration creates a specialized table structure for tracking emergency roadside assistance interactions within the HNTB transportation research platform. This migration establishes the `hntb_tow_and_go` table that serves as a critical component for monitoring emergency service requests, response effectiveness, and user experience with roadside assistance services, enabling comprehensive analysis of transportation resilience and emergency response patterns in mobility research studies.

**Key Features:**
- Dedicated emergency service tracking system with unique tow and go identifiers
- User association maintaining participant relationship integrity across emergency events
- Comprehensive status tracking distinguishing successful and failed service interactions
- Geographic event location capture enabling spatial analysis of emergency patterns
- Dual temporal tracking supporting request-response time analysis
- Request-response lifecycle management with complete temporal audit trail
- Integration support for emergency service provider APIs and response systems

## Technical Analysis

### Database Schema Architecture

The migration implements a comprehensive emergency service tracking schema optimized for response time analysis and service effectiveness monitoring:

```javascript
const tableName = 'hntb_tow_and_go';

exports.up = async function (knex) {
  try {
    await knex.schema.createTable(tableName, (table) => {
      table.integer('tow_and_go_id').unsigned().primary();
      table.string('user_id', 256).notNullable();
      table.tinyint('status').notNullable().comment('0: success, 1: failed');
      table.double('event_lat').notNullable();
      table.double('event_lng').notNullable();
      table.dateTime('logged_on').notNullable().comment('The time that send request to tow and go');
      table.dateTime('updated_on').notNullable().comment('The time that received response from tow and go');
      table.dateTime('created_on').notNullable().defaultTo(knex.raw('CURRENT_TIMESTAMP'));
      table.dateTime('modified_on').notNullable().defaultTo(knex.raw('CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP'));
      table.unique(['tow_and_go_id'], { indexName: 'tow_and_go_id' });
    });
  } catch (e) {
    logger.error(e.message);
    await knex.schema.dropTableIfExists(tableName);
    throw new Error(e);
  }
};
```

### Field Specifications and Emergency Service Integration

**Primary Identification System:**
- `tow_and_go_id`: Unsigned integer serving as unique identifier for each emergency service request
- Primary key constraint ensures data integrity and enables efficient emergency event retrieval
- Unique index optimizes query performance for service-specific operations and response time analysis

**User Correlation Framework:**
- `user_id`: 256-character string maintaining consistent participant identification across emergency events
- Non-nullable constraint ensures every emergency service request is attributed to a research participant
- Supports longitudinal analysis of emergency service usage patterns and user behavior

**Service Status Classification:**
- `status`: Tinyint field with binary classification system (0: success, 1: failed)
- Includes descriptive comment clarifying status code meaning for service outcome analysis
- Non-nullable constraint ensures complete service effectiveness data collection
- Enables statistical analysis of service success rates and failure pattern identification

**Geographic Event Location System:**
- `event_lat`: Double precision field for emergency event latitude coordinates
- `event_lng`: Double precision field for emergency event longitude coordinates
- Both coordinates required (notNullable) ensuring complete spatial data for emergency analysis
- Supports geographic clustering analysis and emergency service coverage optimization

**Temporal Event Lifecycle Tracking:**
- `logged_on`: DateTime field capturing the precise moment of service request initiation
- Includes descriptive comment clarifying this represents request submission time
- `updated_on`: DateTime field capturing the moment of service response completion
- Includes descriptive comment clarifying this represents response receipt time
- Dual temporal tracking enables comprehensive response time analysis and service level monitoring

**Standard Audit Trail Management:**
- `created_on`: Automatic timestamp using MySQL CURRENT_TIMESTAMP for record creation
- `modified_on`: Self-updating timestamp with ON UPDATE CURRENT_TIMESTAMP trigger
- Comprehensive audit trail supporting data integrity and change tracking

### Emergency Service Lifecycle Analysis

**Request-Response Time Measurement:**
The schema design specifically supports emergency service response time analysis through the dual temporal tracking system:

```sql
-- Response time calculation capability
SELECT 
  tow_and_go_id,
  user_id,
  TIMESTAMPDIFF(MINUTE, logged_on, updated_on) as response_time_minutes,
  status
FROM hntb_tow_and_go;
```

**Service Effectiveness Metrics:**
- Binary status classification enables clear success/failure rate calculations
- Geographic data supports spatial analysis of service coverage and effectiveness
- Temporal data enables peak hour analysis and service capacity planning

### Data Integrity and Performance Optimization

**Constraint Implementation:**
```javascript
table.unique(['tow_and_go_id'], {
  indexName: 'tow_and_go_id',
});
```

The unique constraint on tow_and_go_id prevents duplicate emergency service records and maintains consistency across emergency response tracking.

**Error Handling and System Resilience:**
```javascript
catch (e) {
  logger.error(e.message);
  await knex.schema.dropTableIfExists(tableName);
  throw new Error(e);
}
```

**Resilience Features:**
- Automatic table cleanup on migration failure preventing partial schema states
- Comprehensive error logging through centralized @maas/core/log system
- Exception propagation ensuring proper error handling in deployment pipelines
- Transaction safety maintaining database consistency during emergency event processing

## Usage/Integration

### Emergency Service Request Workflow

**Emergency Event Processing Pipeline:**
1. User initiates emergency service request through HNTB platform
2. Request logged with geographic coordinates and precise timestamp
3. Emergency service provider contacted through integrated APIs
4. Service response status tracked and recorded upon completion
5. Response time and effectiveness metrics calculated for research analysis
6. Geographic and temporal patterns analyzed for service optimization

**Research Data Collection Integration:**
- Emergency service usage frequency analysis for transportation resilience studies
- Response time effectiveness measurement supporting service level agreement monitoring
- Geographic clustering analysis identifying emergency hotspots and service gaps
- User behavior pattern analysis enabling proactive emergency response improvements

### Migration Execution Context

**Database Operation Timing:**
- Timestamp: March 13, 2025, 03:23:35 GMT (20250313032335)
- Part of comprehensive HNTB component migration sequence
- Follows foundational migrations building integrated research data platform

**System Integration Architecture:**
- Operates within TSP Job service database environment
- Integrates with emergency service provider APIs for real-time request processing
- Supports both real-time emergency response tracking and batch analytics processing

### Application Service Integration

**Emergency Service Management:**
```javascript
// Example emergency service request processing
const initiateEmergencyService = async (emergencyData) => {
  const serviceRecord = {
    tow_and_go_id: emergencyData.serviceId,
    user_id: emergencyData.userId,
    status: 1, // Initially failed until response received
    event_lat: emergencyData.latitude,
    event_lng: emergencyData.longitude,
    logged_on: new Date(),
    updated_on: new Date() // Will be updated when response received
  };
  
  await knex('hntb_tow_and_go').insert(serviceRecord);
  
  // Initiate emergency service provider contact
  await contactEmergencyProvider(emergencyData);
};

// Update service status upon completion
const updateServiceCompletion = async (serviceId, successful) => {
  await knex('hntb_tow_and_go')
    .where('tow_and_go_id', serviceId)
    .update({
      status: successful ? 0 : 1,
      updated_on: new Date()
    });
};
```

**Research Analytics Integration:**
- Real-time emergency service monitoring dashboards
- Response time analysis for service level optimization
- Geographic emergency pattern analysis supporting infrastructure planning
- User emergency behavior studies enabling proactive service improvements

## Dependencies

### Core Infrastructure Dependencies

**Knex.js Database Management System:**
- Requires TSP Job service Knex configuration for database connectivity and transaction management
- Utilizes MySQL database connection with proper schema modification privileges
- Integrates with Knex migration system for version control and automated deployment processes

**Centralized Logging Infrastructure:**
```javascript
const { logger } = require('@maas/core/log');
```
- Depends on @maas/core/log system for comprehensive error reporting and emergency event audit trails
- Provides structured logging across distributed microservice architecture
- Supports real-time monitoring and debugging of emergency service operations

### Database Platform Requirements

**MySQL Database System:**
- Requires MySQL 5.7+ for advanced timestamp handling and precision coordinate storage
- Utilizes CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP features
- Depends on proper timezone configuration for accurate emergency response time measurement
- Requires geographic data type support for coordinate precision and spatial analysis

**Database Access and Permissions:**
- CREATE TABLE privileges for schema creation and emergency service table establishment
- DROP TABLE privileges for rollback and cleanup operations during migration failures
- INDEX creation permissions for unique constraint implementation and query optimization
- Standard DML privileges (SELECT/INSERT/UPDATE) for emergency event data operations

### External System Integration Dependencies

**Emergency Service Provider APIs:**
- Requires integration with tow and go service provider APIs for request processing
- Depends on service provider response status and confirmation systems
- Integrates with emergency service authentication and authorization frameworks
- Supports real-time communication with multiple emergency service providers

**Geographic and Location Services:**
- Depends on GPS coordinate validation and accuracy verification systems
- Requires integration with reverse geocoding services for location context
- Supports geographic boundary validation and service area verification
- Integrates with mapping services for emergency location visualization

**HNTB Research Platform Integration:**
- Requires consistent user_id format across all HNTB platform components
- Depends on user authentication and emergency contact authorization systems
- Integrates with research data export and emergency pattern analysis pipelines
- Supports correlation with other transportation behavior data for comprehensive analysis

## Code Examples

### Migration Management Operations

**Execute Tow and Go Migration:**
```bash
# Run migration in TSP Job service context
cd allrepo/connectsmart/tsp-job
npx knex migrate:up 20250313032335_hntb_tow_and_go.js --env production

# Verify migration completion and emergency service table structure
npx knex migrate:status | grep tow_and_go
```

**Migration Rollback and Emergency Recovery:**
```bash
# Rollback tow and go migration if required
npx knex migrate:down 20250313032335_hntb_tow_and_go.js --env production

# Verify rollback completion
npx knex migrate:list --completed | grep -v tow_and_go
```

### Emergency Service Data Management

**Emergency Event Data Operations:**
```javascript
const knex = require('./database/connection');

// Log new emergency service request
const logEmergencyServiceRequest = async (emergencyData) => {
  const emergencyRecord = await knex('hntb_tow_and_go').insert({
    tow_and_go_id: emergencyData.serviceId,
    user_id: emergencyData.userId,
    status: 1, // Initially failed status
    event_lat: emergencyData.latitude,
    event_lng: emergencyData.longitude,
    logged_on: new Date(),
    updated_on: new Date()
  });
  
  return emergencyRecord;
};

// Update emergency service completion status
const updateEmergencyServiceStatus = async (serviceId, successful, responseTime) => {
  return await knex('hntb_tow_and_go')
    .where('tow_and_go_id', serviceId)
    .update({
      status: successful ? 0 : 1,
      updated_on: responseTime || new Date()
    });
};

// Retrieve user emergency service history
const getUserEmergencyHistory = async (userId, limitCount = 50) => {
  return await knex('hntb_tow_and_go')
    .where('user_id', userId)
    .select('*')
    .orderBy('logged_on', 'desc')
    .limit(limitCount);
};
```

### Emergency Service Analytics and Research

**Response Time Analysis:**
```javascript
// Calculate average response times by success/failure status
const analyzeResponseTimes = async (startDate, endDate) => {
  return await knex('hntb_tow_and_go')
    .select('status')
    .avg(knex.raw('TIMESTAMPDIFF(MINUTE, logged_on, updated_on) as avg_response_minutes'))
    .count('* as service_count')
    .whereBetween('logged_on', [startDate, endDate])
    .groupBy('status')
    .orderBy('status');
};

// Geographic emergency hotspot analysis
const identifyEmergencyHotspots = async (radiusKm = 5) => {
  return await knex('hntb_tow_and_go')
    .select(
      knex.raw('ROUND(event_lat, 3) as lat_cluster'),
      knex.raw('ROUND(event_lng, 3) as lng_cluster')
    )
    .count('* as emergency_count')
    .groupBy('lat_cluster', 'lng_cluster')
    .having('emergency_count', '>', 5)
    .orderBy('emergency_count', 'desc');
};

// Service effectiveness analysis
const analyzeServiceEffectiveness = async (timeframeDays = 30) => {
  const startDate = new Date(Date.now() - (timeframeDays * 24 * 60 * 60 * 1000));
  
  return await knex('hntb_tow_and_go')
    .select(
      knex.raw('SUM(CASE WHEN status = 0 THEN 1 ELSE 0 END) as successful_services'),
      knex.raw('SUM(CASE WHEN status = 1 THEN 1 ELSE 0 END) as failed_services'),
      knex.raw('COUNT(*) as total_services'),
      knex.raw('(SUM(CASE WHEN status = 0 THEN 1 ELSE 0 END) / COUNT(*)) * 100 as success_rate')
    )
    .where('logged_on', '>', startDate)
    .first();
};
```

### Advanced Emergency Service Research Analytics

**Temporal Pattern Analysis:**
```javascript
// Peak emergency hours analysis
const analyzePeakEmergencyHours = async () => {
  return await knex('hntb_tow_and_go')
    .select(knex.raw('HOUR(logged_on) as emergency_hour'))
    .count('* as emergency_count')
    .avg(knex.raw('TIMESTAMPDIFF(MINUTE, logged_on, updated_on) as avg_response_time'))
    .groupBy(knex.raw('HOUR(logged_on)'))
    .orderBy('emergency_hour');
};

// Day of week emergency patterns
const analyzeDayOfWeekPatterns = async () => {
  return await knex('hntb_tow_and_go')
    .select(knex.raw('DAYOFWEEK(logged_on) as day_of_week'))
    .count('* as emergency_count')
    .sum('status as failed_count')
    .groupBy(knex.raw('DAYOFWEEK(logged_on)'))
    .orderBy('day_of_week');
};

// Comprehensive user emergency profile analysis
const analyzeUserEmergencyProfile = async (userId) => {
  return await knex('hntb_tow_and_go')
    .where('user_id', userId)
    .select(
      knex.raw('COUNT(*) as total_emergencies'),
      knex.raw('SUM(CASE WHEN status = 0 THEN 1 ELSE 0 END) as successful_services'),
      knex.raw('AVG(TIMESTAMPDIFF(MINUTE, logged_on, updated_on)) as avg_response_time'),
      knex.raw('MIN(logged_on) as first_emergency'),
      knex.raw('MAX(logged_on) as last_emergency')
    )
    .first();
};
```

### Data Validation and Emergency Service Integrity

**Emergency Data Validation:**
```javascript
const validateEmergencyServiceData = (emergencyData) => {
  const errors = [];
  
  // Service ID validation
  if (!emergencyData.tow_and_go_id || emergencyData.tow_and_go_id <= 0) {
    errors.push('Valid tow_and_go_id required');
  }
  
  // User ID validation
  if (!emergencyData.user_id || emergencyData.user_id.length > 256) {
    errors.push('Valid user_id required (max 256 characters)');
  }
  
  // Status validation
  if (emergencyData.status !== 0 && emergencyData.status !== 1) {
    errors.push('Status must be 0 (success) or 1 (failed)');
  }
  
  // Geographic coordinate validation
  if (!emergencyData.event_lat || Math.abs(emergencyData.event_lat) > 90) {
    errors.push('Valid latitude required (-90 to 90)');
  }
  
  if (!emergencyData.event_lng || Math.abs(emergencyData.event_lng) > 180) {
    errors.push('Valid longitude required (-180 to 180)');
  }
  
  // Temporal validation
  if (emergencyData.logged_on && emergencyData.updated_on) {
    if (emergencyData.updated_on < emergencyData.logged_on) {
      errors.push('Response time cannot be before request time');
    }
  }
  
  if (errors.length > 0) {
    throw new ValidationError(errors.join(', '));
  }
};
```

**Enhanced Migration Safety and Verification:**
```javascript
// Comprehensive migration with emergency service verification
exports.up = async function (knex) {
  const transaction = await knex.transaction();
  
  try {
    await transaction.schema.createTable('hntb_tow_and_go', (table) => {
      // Complete table definition
    });
    
    // Verify table creation and structure
    const tableExists = await transaction.schema.hasTable('hntb_tow_and_go');
    if (!tableExists) {
      throw new Error('Emergency service table creation failed');
    }
    
    // Verify essential columns exist
    const columns = await transaction('hntb_tow_and_go').columnInfo();
    const criticalColumns = ['tow_and_go_id', 'user_id', 'status', 'event_lat', 'event_lng'];
    
    for (const column of criticalColumns) {
      if (!columns[column]) {
        throw new Error(`Critical emergency service column ${column} not created`);
      }
    }
    
    // Verify geographic coordinate precision
    if (columns.event_lat.type !== 'double' || columns.event_lng.type !== 'double') {
      throw new Error('Geographic coordinates must use double precision');
    }
    
    await transaction.commit();
    logger.info('HNTB Tow and Go emergency service table created and verified successfully');
    
  } catch (error) {
    await transaction.rollback();
    logger.error(`Emergency service migration failed: ${error.message}`);
    throw error;
  }
};
```

**Real-time Emergency Service Monitoring:**
```javascript
// Emergency service real-time monitoring system
const monitorEmergencyServices = async () => {
  const activeEmergencies = await knex('hntb_tow_and_go')
    .where('status', 1)
    .where('updated_on', '>', knex.raw('DATE_SUB(NOW(), INTERVAL 30 MINUTE)'))
    .select('*')
    .orderBy('logged_on', 'desc');
  
  for (const emergency of activeEmergencies) {
    const responseTime = Math.floor((Date.now() - emergency.logged_on.getTime()) / (1000 * 60));
    
    if (responseTime > 60) { // Alert if no response after 60 minutes
      logger.warn(`Emergency service ${emergency.tow_and_go_id} exceeded response threshold: ${responseTime} minutes`);
      
      // Trigger escalation procedures
      await escalateEmergencyService(emergency);
    }
  }
};
```

This migration establishes comprehensive emergency service tracking capabilities within the HNTB research platform, enabling detailed analysis of transportation resilience, emergency response effectiveness, and user behavior during critical mobility situations for evidence-based emergency service optimization and policy development.