# HNTB Trip Migration Documentation

## Quick Summary

The HNTB Trip migration creates the foundational table structure for storing comprehensive trip data in the HNTB transportation research platform. This migration establishes the `hntb_trip` table that serves as the central repository for all trip-related research data, capturing essential trip metadata, geographic information, and temporal characteristics necessary for transportation behavior analysis and policy research studies.

**Key Features:**
- Primary trip identification system with integer-based trip IDs
- User correlation through flexible user_id string fields
- Comprehensive temporal tracking with trip start times and automatic timestamp management
- Geographic coordinate storage for origin locations with latitude/longitude precision
- Travel mode classification for multi-modal transportation analysis
- Flexible address storage supporting various location naming conventions

## Technical Analysis

### Database Schema Structure

The migration implements a robust table schema optimized for transportation research data collection:

```javascript
const tableName = 'hntb_trip';

exports.up = async function (knex) {
  try {
    await knex.schema.createTable(tableName, (table) => {
      table.integer('trip_id').unsigned().primary();
      table.string('user_id', 256).notNullable();
      table.dateTime('started_on').notNullable().comment('The time that start the trip');
      table.integer('travel_mode').unsigned().notNullable();
      table.string('origin_address', 256).nullable();
      table.string('origin_name', 256).nullable();
      table.double('origin_lat').notNullable();
      table.double('origin_lng').notNullable();
      table.dateTime('created_on').notNullable().defaultTo(knex.raw('CURRENT_TIMESTAMP'));
      table.dateTime('modified_on').notNullable().defaultTo(knex.raw('CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP'));
      table.unique(['trip_id'], { indexName: 'trip_id' });
    });
  } catch (e) {
    logger.error(e.message);
    await knex.schema.dropTableIfExists(tableName);
    throw new Error(e);
  }
};
```

### Field Specifications and Data Types

**Primary Identification:**
- `trip_id`: Unsigned integer serving as the primary key for unique trip identification
- Unique constraint ensures data integrity and prevents duplicate trip records

**User Association:**
- `user_id`: 256-character string field linking trips to specific research participants
- Non-nullable constraint ensures every trip is associated with a user

**Temporal Data Management:**
- `started_on`: DateTime field capturing the precise moment trip initiation occurs
- Includes descriptive comment for documentation clarity
- `created_on`: Automatic timestamp generation using MySQL CURRENT_TIMESTAMP
- `modified_on`: Auto-updating timestamp with ON UPDATE CURRENT_TIMESTAMP trigger

**Geographic Coordinate System:**
- `origin_lat`: Double precision field for latitude coordinates
- `origin_lng`: Double precision field for longitude coordinates
- Both coordinates are required (notNullable) ensuring geographic data completeness

**Location Description Fields:**
- `origin_address`: Optional 256-character field for structured address information
- `origin_name`: Optional 256-character field for location identifiers or common names
- Nullable fields provide flexibility for various data collection scenarios

**Transportation Classification:**
- `travel_mode`: Unsigned integer field for standardized mode categorization
- Required field ensuring every trip has associated transportation method data

### Error Handling and Transaction Safety

The migration implements comprehensive error handling with automatic rollback capabilities:

```javascript
catch (e) {
  logger.error(e.message);
  await knex.schema.dropTableIfExists(tableName);
  throw new Error(e);
}
```

**Safety Features:**
- Automatic table cleanup on migration failure
- Comprehensive error logging through @maas/core/log system
- Exception re-throwing for proper error propagation
- Transaction safety ensuring database consistency

### Rollback Implementation

```javascript
exports.down = async function (knex) {
  await knex.schema.dropTable(tableName);
};
```

The rollback function provides clean migration reversal by completely removing the table structure.

## Usage/Integration

### Migration Execution Context

**Database Connection:**
- Utilizes Knex.js query builder for database schema management
- Operates within the TSP Job service database context
- Integrates with the broader HNTB research platform infrastructure

**Migration Timing:**
- Timestamp: March 12, 2025, 06:36:41 GMT (20250312063641)
- Represents foundational schema creation for HNTB trip data collection
- Precedes related HNTB component migrations (ratings, passes, alerts)

### Integration with HNTB Research Platform

**Data Collection Workflow:**
1. Trip initiation triggers database record creation
2. Geographic coordinates captured from device GPS systems
3. Travel mode classification applied based on detection algorithms
4. User association maintained through authentication system integration
5. Temporal data automatically managed through database triggers

**Research Data Pipeline:**
- Trip records serve as foundation for behavioral analysis
- Geographic data enables spatial analysis and route optimization studies
- Temporal information supports time-series analysis and pattern recognition
- User correlation facilitates longitudinal behavior tracking

### Application Integration Points

**Service Layer Integration:**
```javascript
// Example usage in TSP Job services
const tripData = {
  trip_id: generateTripId(),
  user_id: authenticatedUser.id,
  started_on: new Date(),
  travel_mode: detectTravelMode(),
  origin_lat: locationData.latitude,
  origin_lng: locationData.longitude,
  origin_address: await reverseGeocode(locationData),
  origin_name: locationData.placeName
};

await knex('hntb_trip').insert(tripData);
```

**Analytics Integration:**
- Supports aggregation queries for trip pattern analysis
- Enables geographic clustering and route optimization
- Facilitates comparative studies across different user segments
- Powers real-time dashboard analytics and reporting systems

## Dependencies

### Core Framework Dependencies

**Knex.js Query Builder:**
- Version compatibility with TSP Job service Knex configuration
- Requires MySQL database connection and proper schema permissions
- Utilizes Knex migration system for version control and deployment

**@maas/core/log System:**
```javascript
const { logger } = require('@maas/core/log');
```
- Integrates with centralized logging infrastructure
- Provides structured error reporting and audit trail capabilities
- Supports distributed logging across microservice architecture

### Database Requirements

**MySQL Database System:**
- Requires MySQL 5.7+ for proper timestamp handling
- Utilizes CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP features
- Depends on proper timezone configuration for accurate temporal data

**Schema Permissions:**
- CREATE TABLE privileges for schema modification
- DROP TABLE privileges for rollback operations
- INDEX creation permissions for unique constraint implementation

### Platform Integration Dependencies

**HNTB Research Platform:**
- Coordinates with user management systems for user_id validation
- Integrates with geographic services for coordinate validation
- Connects with travel mode detection algorithms
- Supports research data export and analysis pipelines

**TSP Job Service Architecture:**
- Operates within TSP Job microservice context
- Utilizes shared database connection pooling
- Integrates with job scheduling and background processing systems

## Code Examples

### Migration Execution Commands

**Running the Migration:**
```bash
# Execute migration in TSP Job service context
cd allrepo/connectsmart/tsp-job
npx knex migrate:up --env production

# Verify migration status
npx knex migrate:status
```

**Migration Rollback:**
```bash
# Rollback specific migration
npx knex migrate:down --env production

# Rollback to specific version
npx knex migrate:rollback --to=20250312063641
```

### Database Interaction Examples

**Trip Data Insertion:**
```javascript
const knex = require('./database/connection');

// Insert new trip record
const newTrip = await knex('hntb_trip').insert({
  trip_id: 123456,
  user_id: 'user_research_participant_001',
  started_on: '2025-03-12 14:30:00',
  travel_mode: 2, // Public transit
  origin_address: '123 Main Street, Austin, TX 78701',
  origin_name: 'Downtown Transit Center',
  origin_lat: 30.2672,
  origin_lng: -97.7431
});

// Query trip data with geographic filtering
const nearbyTrips = await knex('hntb_trip')
  .whereBetween('origin_lat', [30.0, 31.0])
  .whereBetween('origin_lng', [-98.0, -97.0])
  .where('travel_mode', 2)
  .orderBy('started_on', 'desc')
  .limit(100);
```

**Research Analytics Queries:**
```javascript
// Trip mode distribution analysis
const modeDistribution = await knex('hntb_trip')
  .select('travel_mode')
  .count('* as trip_count')
  .groupBy('travel_mode')
  .orderBy('trip_count', 'desc');

// Temporal pattern analysis
const hourlyPatterns = await knex('hntb_trip')
  .select(knex.raw('HOUR(started_on) as hour'))
  .count('* as trips')
  .groupBy(knex.raw('HOUR(started_on)'))
  .orderBy('hour');

// Geographic clustering analysis
const originClusters = await knex('hntb_trip')
  .select('origin_lat', 'origin_lng')
  .count('* as frequency')
  .groupBy('origin_lat', 'origin_lng')
  .having('frequency', '>', 5)
  .orderBy('frequency', 'desc');
```

### Error Handling Patterns

**Migration Safety Implementation:**
```javascript
// Robust migration with comprehensive error handling
exports.up = async function (knex) {
  const transaction = await knex.transaction();
  
  try {
    await transaction.schema.createTable('hntb_trip', (table) => {
      // Table definition
    });
    
    // Verify table creation
    const tableExists = await transaction.schema.hasTable('hntb_trip');
    if (!tableExists) {
      throw new Error('Table creation verification failed');
    }
    
    await transaction.commit();
    logger.info('HNTB Trip table created successfully');
    
  } catch (error) {
    await transaction.rollback();
    logger.error(`Migration failed: ${error.message}`);
    throw error;
  }
};
```

**Data Validation and Constraints:**
```javascript
// Application-level validation before database insertion
const validateTripData = (tripData) => {
  const errors = [];
  
  if (!tripData.trip_id || tripData.trip_id <= 0) {
    errors.push('Valid trip_id required');
  }
  
  if (!tripData.user_id || tripData.user_id.length > 256) {
    errors.push('Valid user_id required (max 256 characters)');
  }
  
  if (!tripData.origin_lat || Math.abs(tripData.origin_lat) > 90) {
    errors.push('Valid latitude required (-90 to 90)');
  }
  
  if (!tripData.origin_lng || Math.abs(tripData.origin_lng) > 180) {
    errors.push('Valid longitude required (-180 to 180)');
  }
  
  if (errors.length > 0) {
    throw new ValidationError(errors.join(', '));
  }
};
```

This migration establishes the critical foundation for HNTB transportation research data collection, providing robust data storage capabilities for comprehensive trip analysis and behavioral research studies.